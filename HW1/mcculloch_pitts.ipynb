{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhAYF-3i_dI_"
      },
      "outputs": [],
      "source": [
        "def mcculloch_pitts(input_string):\n",
        "    # Define the initial state as state 0\n",
        "    state = 0\n",
        "\n",
        "    # Define a dictionary to represent the state transitions\n",
        "    transitions = {\n",
        "        (0, '0'): 0,\n",
        "        (0, '1'): 1,\n",
        "        (1, '0'): 2,\n",
        "        (1, '1'): 1,\n",
        "        (2, '0'): 3,\n",
        "        (2, '1'): 1,\n",
        "        (3, '0'): 3,\n",
        "        (3, '1'): 3\n",
        "    }\n",
        "\n",
        "    # Iterate through the input string\n",
        "    for char in input_string:\n",
        "        # Update the state based on the current state and input\n",
        "        state = transitions.get((state, char), state)\n",
        "\n",
        "        # Print the current state\n",
        "        print(f\"State {state}\")\n",
        "\n",
        "# Input string\n",
        "input_string = \"00101100101\"\n",
        "\n",
        "# Call the function with the input string\n",
        "mcculloch_pitts(input_string)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the McCulloch-Pitts neuron as a custom module\n",
        "class McCullochPittsNeuron(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(McCullochPittsNeuron, self).__init__()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Implement the McCulloch-Pitts logic\n",
        "        if inputs == 1:\n",
        "            return torch.tensor([1.0])\n",
        "        else:\n",
        "            return torch.tensor([0.0])\n",
        "\n",
        "# Define the finite state machine\n",
        "def run_fsm(input_string):\n",
        "    state = 0\n",
        "\n",
        "    # Create an instance of the McCulloch-Pitts neuron\n",
        "    neuron = McCullochPittsNeuron()\n",
        "\n",
        "    # Iterate through the input string\n",
        "    for char in input_string:\n",
        "        char = int(char)  # Convert the character to an integer\n",
        "        char_tensor = torch.tensor([char], dtype=torch.float32)\n",
        "\n",
        "        # Calculate the output of the neuron based on the current state and input\n",
        "        output = neuron(char_tensor)\n",
        "\n",
        "        # Print the current state and neuron output\n",
        "        print(f\"State {state}, Neuron Output: {output.item()}\")\n",
        "\n",
        "        # Update the state based on the neuron output\n",
        "        state = int(output.item())\n",
        "\n",
        "# Input string\n",
        "input_string = \"001100101\"\n",
        "\n",
        "# Call the FSM function with the input string\n",
        "run_fsm(input_string)\n"
      ],
      "metadata": {
        "id": "hxxxv9hQ_v8E",
        "outputId": "5b5b06c2-1f58-4f62-e288-88b5a254cfe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State 0, Neuron Output: 0.0\n",
            "State 0, Neuron Output: 0.0\n",
            "State 0, Neuron Output: 1.0\n",
            "State 1, Neuron Output: 1.0\n",
            "State 1, Neuron Output: 0.0\n",
            "State 0, Neuron Output: 0.0\n",
            "State 0, Neuron Output: 1.0\n",
            "State 1, Neuron Output: 0.0\n",
            "State 0, Neuron Output: 1.0\n"
          ]
        }
      ]
    }
  ]
}